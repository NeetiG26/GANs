{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pose Guided Person Image Generation\n",
    "With an additional input of the pose, we can transform an image into different poses.\n",
    "\n",
    "Source : https://arxiv.org/pdf/1705.09368.pdf\n",
    "\n",
    "GitHub Link : https://github.com/charliememory/Pose-Guided-Person-Image-Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Pictures/arch_posegen.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We summarize the network architecture of the proposed model PG2. At stage-I, the encoder of G1consists of N residual blocks and one fully-connected layer , where N depends on the size of input.Each residual block consists of two convolution layers with stride=1 followed by one sub-samplingconvolution layer with stride=2 except the last block.  At stage-II, the encoder of G2 has a fullyconvolutional architecture including N-2 convolution blocks. Each block consists of two convolutionlayers with stride=1 and one sub-sampling convolution layer with stride=2.  Decoders in both G1 and G2 are symmetric to corresponding encoders. Besides, there are shortcut connections betweendecoders and encoders, which can be seen in Figure 2.  In G1 and G2, no batch normalization ordropout are applied.  All convolution layers consist of 3Ã—3 filters and the number of filters areincreased linearly with each block. We apply rectified linear unit (ReLU) to each layer except thefully connected layer and the output convolution layer.  For the discriminator, we adopt the samenetwork architecture as DCGAN except the size of the input convolution layer due to differentimage resolutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unpaired Image-to-Image Translation using CycleGAN\n",
    "For example, it can transform pictures between zebras and horses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/800/1*O1oZ2w1syvi9RYs2LoKEGg.jpeg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://cdn-images-1.medium.com/max/800/1*O1oZ2w1syvi9RYs2LoKEGg.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PixelDTGAN\n",
    "Suggesting merchandise based on celebrity pictures has been popular for fashion blogger and e-commerce. PixelDTGAN creates clothing images and styles from an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/800/1*9siTthZHsaKKdvftr43Ojg.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://cdn-images-1.medium.com/max/800/1*9siTthZHsaKKdvftr43Ojg.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High-resolution image synthesis\n",
    "\n",
    "Generating images from a semantic map. Collecting samples are very expensive. We have trying to supplement training dataset with generated data to lower development cost. It will be handy to generate videos in training autonomous cars rather than see them cruising in your neighborhood.\n",
    "\n",
    "Source: https://arxiv.org/pdf/1711.11585.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/800/1*63YXMwXFGNSEoQvys1sqYA.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://cdn-images-1.medium.com/max/800/1*63YXMwXFGNSEoQvys1sqYA.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text to image (StackGAN)\n",
    "\n",
    "Text to image is one of the earlier application of domain-transfer GAN. We input a sentence and generate multiple images fitting the description.\n",
    "\n",
    "Source: https://arxiv.org/pdf/1612.03242v1.pdf\n",
    "\n",
    "GitHub Link: https://github.com/hanzhanggit/StackGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/800/1*qASfnkDHhealTIC8ev6rag.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://cdn-images-1.medium.com/max/800/1*qASfnkDHhealTIC8ev6rag.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
