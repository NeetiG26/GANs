{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applications of GANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation of Anime characters\n",
    "Here we can give attributes to the generator for the character we want to generate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source : https://arxiv.org/pdf/1708.05509.pdf\n",
    "\n",
    "GitHub Link : https://github.com/VincentXWD/CreateGirlsMoe/blob/master/src/model/gan.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/800/1*CcqEeJAa6cOBP8a713YR-w.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://cdn-images-1.medium.com/max/800/1*CcqEeJAa6cOBP8a713YR-w.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Processing:\n",
    "1. Image Collection - www.getchu.com\n",
    "\n",
    "First execute a SQL query on ErogameScape’s Web SQL API page5 to get the Getchu page link for each game.\n",
    "Then download images and apply lbpcascade animeface, an anime character face detector, to each image and get bounding box for faces.\n",
    "Then zoom out the bounding box by a rate of 1.5x to retain information like hair\n",
    "\n",
    "2. Tag Estimation\n",
    "\n",
    "use Illustration2Vec, a CNN-based tool for estimating tags of anime illustrations for our purpose. Given an anime image, this network can predict probabilities of belonging to 512 kinds of general attributes (tags) such as “smile” and “weapon”, among which we select 34 related tags suitable for our task.\n",
    "\n",
    "3. Visualization\n",
    "\n",
    "To show the image preparation and the performance of tag estimation through visualization.\n",
    "As an approximation, we apply the Illustration2Vec feature extractor, which largely shares architecture and weights with Illustration2Vec tag estimator, on each image for a 4096-dimension feature vector, and project feature vectors onto a 2D space using t-SNE. We observe that character images with similar visual attributes are placed closely. Due to the shared weights, we believe this also indicates the good performance in tag estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Super resolution\n",
    "\n",
    "Create super-resolution images from the lower resolution. This is one area where GAN shows very impressive result with immediate commercial possibility.\n",
    "\n",
    "Source - https://arxiv.org/pdf/1609.04802.pdf\n",
    "\n",
    "GitHub Link - https://github.com/brade31919/SRGAN-tensorflow\n",
    "\n",
    "Dataset - We  perform  experiments  on  three  widely  used  bench-mark datasets Set5[3],Set14[69] and BSD100, the testing set of BSD300 [41]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/800/1*Bir4_sw_41jr2nsTjyjrnA.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://cdn-images-1.medium.com/max/800/1*Bir4_sw_41jr2nsTjyjrnA.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progressive growing of GANs\n",
    "\n",
    "Progressive GAN is probably one of the first GAN showing commercial-like image quality. \n",
    "\n",
    "Source: https://arxiv.org/pdf/1710.10196.pdf\n",
    "\n",
    "GitHub Link: https://github.com/zhangqianhui/progressive_growing_of_gans_tensorflow\n",
    "\n",
    "Data Source: We evaluate our contributions using the CELEBA, LSUN, CIFAR10 datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/800/1*fdFgXwhCqd0V6Z-PiM0_wQ.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://cdn-images-1.medium.com/max/800/1*fdFgXwhCqd0V6Z-PiM0_wQ.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text to Image Synthesis\n",
    "\n",
    "Text to image is one of the earlier application of domain-transfer GAN. We input a sentence and generate multiple images fitting the description.\n",
    "\n",
    "Source: https://arxiv.org/pdf/1605.05396.pdf\n",
    "\n",
    "GitHub Link: https://github.com/zsdonghao/text-to-image\n",
    "\n",
    "Dataset:  Oxford-102 Flowers dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/800/1*XQHKAej4MRnCOs7x_lhwNQ.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://cdn-images-1.medium.com/max/800/1*XQHKAej4MRnCOs7x_lhwNQ.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate 3D objects\n",
    "\n",
    "This is one often quoted paper in creating 3D objects with GAN.\n",
    "\n",
    "Source: http://papers.nips.cc/paper/6096-learning-a-probabilistic-latent-space-of-object-shapes-via-3d-generative-adversarial-modeling.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/800/1*efvY2GU-yju-5JeexAFupQ.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://cdn-images-1.medium.com/max/800/1*efvY2GU-yju-5JeexAFupQ.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medical (Anomaly Detection)\n",
    "\n",
    "GAN can also extend to other industry, for example medical in tumor detection.\n",
    "\n",
    "Source:https://arxiv.org/pdf/1703.05921.pdf\n",
    "\n",
    "Github Link: https://github.com/tkwoo/anogan-keras/blob/master/anogan.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://cdn-images-1.medium.com/max/800/1*iu2hvOIRXZ5pCQc_GaZQrw.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://cdn-images-1.medium.com/max/800/1*iu2hvOIRXZ5pCQc_GaZQrw.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
